#!/usr/bin/env python3
"""
Test OmniMind with Cloud LLMs (OpenAI, Anthropic, Google)
"""

import sys
import os
import asyncio
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("""
üß† Testing OmniMind with Cloud LLMs
====================================
""")

async def test_providers():
    """Test each cloud provider."""
    from src.core.omnimind_enhanced import OmniMindEnhanced
    
    # Initialize OmniMind
    print("1Ô∏è‚É£ Initializing OmniMind with cloud providers...")
    om = OmniMindEnhanced()
    
    # Get provider info
    info = om.get_provider_info()
    print(f"\n‚úÖ Available Providers:")
    for provider in info['available_providers']:
        print(f"   ‚Ä¢ {provider}")
    
    # Add some context
    print("\n2Ô∏è‚É£ Adding test memories...")
    om.remember("We're testing OmniMind with multiple cloud LLMs")
    om.remember("OmniMind uses GPT-4, Claude Opus, and Gemini Pro")
    om.remember("The goal is to provide the best answers through consensus")
    print("‚úÖ Added 3 test memories")
    
    # Test individual providers
    print("\n3Ô∏è‚É£ Testing each provider individually...")
    
    providers_to_test = ['openai', 'anthropic', 'google']
    
    for provider in providers_to_test:
        if provider in info['available_providers']:
            print(f"\n   Testing {provider.upper()}...")
            try:
                response = await om.think_async(
                    "Hello! What model are you and what makes you special?",
                    providers=[provider],
                    use_consensus=False
                )
                print(f"   ‚úÖ {provider}: {response[:100]}...")
            except Exception as e:
                print(f"   ‚ùå {provider} error: {e}")
    
    # Test consensus
    print("\n4Ô∏è‚É£ Testing multi-model consensus...")
    print("   Question: 'What are the key benefits of using multiple LLMs together?'")
    
    try:
        consensus_response = await om.think_async(
            "What are the key benefits of using multiple LLMs together?",
            use_consensus=True,
            providers=['openai', 'anthropic', 'google']
        )
        print("\n   ü§ù Consensus Response:")
        print("   " + "-" * 50)
        print(f"   {consensus_response[:500]}...")
        print("   " + "-" * 50)
    except Exception as e:
        print(f"   ‚ùå Consensus error: {e}")
    
    print("\n‚úÖ All tests complete!")
    print("\nüìä Summary:")
    print(f"   ‚Ä¢ Cloud Providers: {len(info['cloud_providers'])}")
    print(f"   ‚Ä¢ Local Providers: {len(info['local_providers'])}")
    print(f"   ‚Ä¢ Total Available: {len(info['available_providers'])}")

# Run the async test
print("Starting tests...\n")
asyncio.run(test_providers())

print("""

‚ú® Success! OmniMind is working with cloud LLMs!

You now have access to:
‚Ä¢ GPT-4 Turbo (OpenAI)
‚Ä¢ Claude 3 Opus (Anthropic)
‚Ä¢ Gemini Pro (Google)
‚Ä¢ Ollama models (Local)

üöÄ Start using OmniMind:
   python3 src/main.py cli  # Interactive terminal
   python3 src/main.py web  # Browser interface
   
üí° Example commands:
   python3 src/main.py ask "What should I build next?"
   python3 src/main.py ask "Explain quantum computing" --consensus
""")