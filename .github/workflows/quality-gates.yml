name: Quality Gates

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: "3.9"
  NODE_VERSION: "18"

jobs:
  # Pre-commit hooks and basic checks
  pre-commit:
    runs-on: ubuntu-latest
    name: Pre-commit checks
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pre-commit
    
    - name: Cache pre-commit
      uses: actions/cache@v3
      with:
        path: ~/.cache/pre-commit
        key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
    
    - name: Run pre-commit
      run: pre-commit run --all-files --show-diff-on-failure

  # Code quality analysis
  code-quality:
    runs-on: ubuntu-latest
    name: Code Quality Analysis
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 pylint mypy black isort bandit safety
    
    - name: Run Black (code formatting)
      run: black --check --diff .
    
    - name: Run isort (import sorting)
      run: isort --check-only --diff .
    
    - name: Run flake8 (linting)
      run: flake8 src/ tests/
    
    - name: Run pylint (advanced linting)
      run: pylint src/ --fail-under=8.0
    
    - name: Run mypy (type checking)
      run: mypy src/ --ignore-missing-imports
      continue-on-error: true  # Allow type errors initially
    
    - name: Run custom quality checks
      run: python tools/quality_checks.py
      continue-on-error: true

  # Security scanning
  security:
    runs-on: ubuntu-latest
    name: Security Scan
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install bandit safety semgrep
    
    - name: Run Bandit (security linting)
      run: bandit -r src/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Run Safety (vulnerability scanning)
      run: safety check --json --output safety-report.json
      continue-on-error: true
    
    - name: Run dependency security check
      run: python tools/dependency_check.py
      continue-on-error: true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # Testing
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]
    name: Tests (Python ${{ matrix.python-version }})
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-mock pytest-xdist pytest-benchmark pytest-timeout
    
    - name: Run unit tests with coverage
      run: |
        pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --cov-fail-under=80 --timeout=300
      timeout-minutes: 10
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --maxfail=5 --timeout=600
      env:
        # Mock API keys for testing
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY || 'test-key' }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY || 'test-key' }}
      timeout-minutes: 15
      continue-on-error: true
    
    - name: Run security tests
      run: |
        pytest tests/security/ -v --timeout=300
      timeout-minutes: 8
    
    - name: Run performance regression tests
      run: |
        pytest tests/performance/ -v -m "performance and not slow" --timeout=600
      timeout-minutes: 12
      continue-on-error: true
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella-${{ matrix.python-version }}
        fail_ci_if_error: false
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          htmlcov/
          .coverage
          pytest.xml

  # Performance benchmarking
  performance:
    runs-on: ubuntu-latest
    name: Performance Benchmarks
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler
    
    - name: Run performance tests
      run: |
        pytest tests/performance/ -v --benchmark-only --benchmark-json=benchmark.json
      continue-on-error: true
    
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
      continue-on-error: true

  # Documentation build
  docs:
    runs-on: ubuntu-latest
    name: Documentation Build
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install sphinx sphinx-rtd-theme myst-parser
    
    - name: Build documentation
      run: |
        cd docs
        make html
      continue-on-error: true
    
    - name: Upload docs artifact
      uses: actions/upload-artifact@v3
      with:
        name: documentation
        path: docs/_build/html/

  # Dependency analysis
  dependencies:
    runs-on: ubuntu-latest
    name: Dependency Analysis
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pip-audit pipdeptree safety
    
    - name: Generate dependency tree
      run: pipdeptree --json > dependency-tree.json
    
    - name: Check for known vulnerabilities
      run: pip-audit --format=json --output=vulnerabilities.json
      continue-on-error: true
    
    - name: Run custom dependency checks
      run: python tools/dependency_check.py
      continue-on-error: true
    
    - name: Upload dependency reports
      uses: actions/upload-artifact@v3
      with:
        name: dependency-reports
        path: |
          dependency-tree.json
          vulnerabilities.json

  # Build and packaging
  build:
    runs-on: ubuntu-latest
    name: Build Package
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine check-manifest
    
    - name: Check manifest
      run: check-manifest
      continue-on-error: true
    
    - name: Build package
      run: python -m build
    
    - name: Check package
      run: twine check dist/*
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: python-package
        path: dist/

  # Quality gate summary
  quality-gate:
    runs-on: ubuntu-latest
    name: Quality Gate Summary
    needs: [pre-commit, code-quality, security, test, performance, docs, dependencies, build]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Quality Gate Analysis
      run: |
        echo "## Quality Gate Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Pre-commit | ${{ needs.pre-commit.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Code Quality | ${{ needs.code-quality.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security | ${{ needs.security.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Tests | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance | ${{ needs.performance.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Documentation | ${{ needs.docs.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Dependencies | ${{ needs.dependencies.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Build | ${{ needs.build.result }} |" >> $GITHUB_STEP_SUMMARY
        
        # Fail if critical checks failed
        if [[ "${{ needs.pre-commit.result }}" == "failure" || "${{ needs.test.result }}" == "failure" || "${{ needs.build.result }}" == "failure" ]]; then
          echo "❌ Critical quality gates failed!"
          exit 1
        else
          echo "✅ All critical quality gates passed!"
        fi