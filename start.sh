#!/bin/bash

# OmniMind Startup Script
# Run your FREE local AI system!

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                            â•‘"
echo "â•‘        ðŸ§  OmniMind v2.0 ðŸ§                 â•‘"
echo "â•‘                                            â•‘"
echo "â•‘   Your FREE Persistent Intelligence        â•‘"
echo "â•‘   5 Local LLMs â€¢ Perfect Memory â€¢ \$0/mo    â•‘"
echo "â•‘                                            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed!"
    echo "Please install Ollama first:"
    echo "  curl -fsSL https://ollama.ai/install.sh | sh"
    exit 1
fi

# Start Ollama service if not running
if ! pgrep -x "ollama" > /dev/null; then
    echo "ðŸš€ Starting Ollama service..."
    ollama serve &>/dev/null &
    sleep 3
fi

# Check available models
echo "ðŸ“¦ Checking local models..."
MODELS=$(ollama list 2>/dev/null | tail -n +2 | wc -l)
if [ "$MODELS" -eq 0 ]; then
    echo "âš ï¸  No models found. Download them with:"
    echo "  ./download_best_models.sh"
    echo ""
fi

# Show available models
echo ""
echo "Available Local Models (FREE!):"
ollama list 2>/dev/null | grep -E "(llama3.2|mistral|phi3|deepseek|gemma2)" | while read -r line; do
    echo "  âœ… $line"
done

echo ""
echo "Choose how to run OmniMind:"
echo ""
echo "  1) ðŸ’¬ CLI - Interactive terminal"
echo "  2) ðŸŒ Web - Browser interface (recommended)"
echo "  3) ðŸŽ¯ Quick - Ask a single question"
echo "  4) ðŸ§ª Demo - Run quick demo"
echo "  5) ðŸ“Š Info - Show system info"
echo ""

read -p "Enter choice (1-5): " choice

case $choice in
    1)
        echo ""
        echo "Starting CLI interface..."
        echo "Commands: /help, /models, /consensus, /search"
        echo ""
        python3 src/main.py cli
        ;;
    2)
        echo ""
        echo "Starting web interface..."
        echo "Opening browser at http://localhost:7860"
        echo "Press Ctrl+C to stop"
        echo ""
        python3 src/main.py web
        ;;
    3)
        echo ""
        read -p "Ask your question: " question
        echo ""
        python3 src/main.py ask "$question"
        ;;
    4)
        echo ""
        echo "Running demo..."
        python3 src/main.py demo
        ;;
    5)
        echo ""
        echo "System Information:"
        echo "==================="
        echo ""
        echo "ðŸ–¥ï¸  System:"
        echo "  â€¢ OS: $(uname -s)"
        echo "  â€¢ Python: $(python3 --version)"
        echo "  â€¢ Ollama: $(ollama --version 2>/dev/null | head -1)"
        echo ""
        echo "ðŸ“¦ Models:"
        ollama list 2>/dev/null | tail -n +2 | head -5
        echo ""
        echo "ðŸ’¾ Storage:"
        echo "  â€¢ Models: $(du -sh ~/.ollama/models 2>/dev/null | cut -f1)"
        echo "  â€¢ OmniMind Data: $(du -sh data 2>/dev/null | cut -f1)"
        echo ""
        echo "ðŸ’° Cost Analysis:"
        echo "  â€¢ API Costs: \$0/month"
        echo "  â€¢ Rate Limits: None"
        echo "  â€¢ Privacy: 100% local"
        echo ""
        ;;
    *)
        echo "Invalid choice. Exiting."
        exit 1
        ;;
esac